library(httr)
username <- "ccc5ed112836c62496dfc6cf6afeeea9"
wkid <- "1262158"
req <- GET("https://toggl.com/reports/api/v2/summary",
authenticate(user=username, password="api_token"),
query=list(user_agent="clunch", workspace_id=wkid, since=Sys.Date()))
parsed <- fromJSON(content(req, "text"), flatten=T)
timeByWBS <- parsed$data[,c("time","title.project")]
timeByWBS$time <- round(timeByWBS$time/(60*60*1000), 1)
timeByWBS
View(iris)
class(iris)
library(jsonlite)
library(httr)
username <- "ccc5ed112836c62496dfc6cf6afeeea9"
wkid <- "1262158"
req <- GET("https://toggl.com/reports/api/v2/summary",
authenticate(user=username, password="api_token"),
query=list(user_agent="clunch", workspace_id=wkid, since="2019-05-02")
parsed <- fromJSON(content(req, "text"), flatten=T)
timeByWBS <- parsed$data[,c("time","title.project")]
timeByWBS$time <- round(timeByWBS$time/(60*60*1000), 1)
timeByWBS
username <- "ccc5ed112836c62496dfc6cf6afeeea9"
wkid <- "1262158"
req <- GET("https://toggl.com/reports/api/v2/summary",
authenticate(user=username, password="api_token"),
query=list(user_agent="clunch", workspace_id=wkid, since="2019-05-02"))
parsed <- fromJSON(content(req, "text"), flatten=T)
timeByWBS <- parsed$data[,c("time","title.project")]
timeByWBS$time <- round(timeByWBS$time/(60*60*1000), 1)
timeByWBS
library(jsonlite)
library(httr)
username <- "ccc5ed112836c62496dfc6cf6afeeea9"
wkid <- "1262158"
req <- GET("https://toggl.com/reports/api/v2/summary",
authenticate(user=username, password="api_token"),
query=list(user_agent="clunch", workspace_id=wkid, since=Sys.Date()))
parsed <- fromJSON(content(req, "text"), flatten=T)
timeByWBS <- parsed$data[,c("time","title.project")]
timeByWBS$time <- round(timeByWBS$time/(60*60*1000), 1)
timeByWBS
library(neonUtilities)
wdp <- loadByProduct(dpID="DP1.00013.001")
wdp <- loadByProduct(dpID="DP1.00013.001")
wdp <- loadByProduct(dpID="DP1.00013.001")
library(jsonlite)
library(httr)
username <- "ccc5ed112836c62496dfc6cf6afeeea9"
wkid <- "1262158"
req <- GET("https://toggl.com/reports/api/v2/summary",
authenticate(user=username, password="api_token"),
query=list(user_agent="clunch", workspace_id=wkid, since=Sys.Date()))
parsed <- fromJSON(content(req, "text"), flatten=T)
timeByWBS <- parsed$data[,c("time","title.project")]
timeByWBS$time <- round(timeByWBS$time/(60*60*1000), 1)
timeByWBS
library(jsonlite)
library(httr)
username <- "ccc5ed112836c62496dfc6cf6afeeea9"
wkid <- "1262158"
req <- GET("https://toggl.com/reports/api/v2/summary",
authenticate(user=username, password="api_token"),
query=list(user_agent="clunch", workspace_id=wkid, since=Sys.Date()))
parsed <- fromJSON(content(req, "text"), flatten=T)
timeByWBS <- parsed$data[,c("time","title.project")]
timeByWBS$time <- round(timeByWBS$time/(60*60*1000), 1)
timeByWBS
library(jsonlite)
library(httr)
username <- "ccc5ed112836c62496dfc6cf6afeeea9"
wkid <- "1262158"
req <- GET("https://toggl.com/reports/api/v2/summary",
authenticate(user=username, password="api_token"),
query=list(user_agent="clunch", workspace_id=wkid, since=Sys.Date()))
parsed <- fromJSON(content(req, "text"), flatten=T)
timeByWBS <- parsed$data[,c("time","title.project")]
timeByWBS$time <- round(timeByWBS$time/(60*60*1000), 1)
timeByWBS
library(jsonlite)
library(httr)
username <- "ccc5ed112836c62496dfc6cf6afeeea9"
wkid <- "1262158"
req <- GET("https://toggl.com/reports/api/v2/summary",
authenticate(user=username, password="api_token"),
query=list(user_agent="clunch", workspace_id=wkid, since=Sys.Date()))
parsed <- fromJSON(content(req, "text"), flatten=T)
timeByWBS <- parsed$data[,c("time","title.project")]
timeByWBS$time <- round(timeByWBS$time/(60*60*1000), 1)
timeByWBS
library(neonUtilities)
wdp <- loadByProduct(dpID="DP1.00013.001")
View(wdp$wdp_chemLab)
View(wdp$wdp_chemLab)
wdp.TALL <- loadByProduct(dpID="DP1.00013.001", site="TALL", package="expanded")
View(wdp.TALL$wdp_sensor)
iso <- loadByProduct(dpID="DP1.00038.001")
View(iso$wdi_isoPerSample)
iso.TALL <- loadByProduct(dpID="DP1.00038.001", site="TALL", package="expanded")
iso.WREF <- loadByProduct(dpID="DP1.00038.001", site="WREF", package="expanded")
dpm <- loadByProduct(dpID="DP1.00101.001")
View(dpm$dpm_lab)
dpm.RMNP <- loadByProduct(dpID="DP1.00101.001", site="RMNP", package="expanded")
View(dpm.RMNP$dpm_sensor)
library(neonUtilities)
iso <- loadByProduct(dpID="DP1.00038.001", package="expanded")
library(jsonlite)
library(httr)
username <- "ccc5ed112836c62496dfc6cf6afeeea9"
wkid <- "1262158"
req <- GET("https://toggl.com/reports/api/v2/summary",
authenticate(user=username, password="api_token"),
query=list(user_agent="clunch", workspace_id=wkid, since=Sys.Date()))
parsed <- fromJSON(content(req, "text"), flatten=T)
timeByWBS <- parsed$data[,c("time","title.project")]
timeByWBS$time <- round(timeByWBS$time/(60*60*1000), 1)
timeByWBS
devtools::install_github('NEONScience/NEON-utilities/neonUtilities', ref='eddy')
library(neonUtilities)
zipsByProduct(dpID="DP4.00200.001", package="basic",
site=c("BONA", "CPER"), startdate="2017-12", enddate="2018-02",
savepath="/Users/clunch/Desktop", check.size=F)
flux <- stackEC(filepath="/Users/clunch/Desktop/filesToStack00200/", level="dp04")
View(flux$BONA)
level <- "dp01"
filepath <- "/Users/clunch/Desktop/filesToStack00200/"
var <- "rtioMoleDryCo2"
avg <- 30
if(substring(filepath, nchar(filepath)-3, nchar(filepath))==".zip") {
outpath <- gsub(".zip", "", filepath)
if(!dir.exists(outpath)) {
dir.create(outpath)
}
utils::unzip(filepath, exdir=outpath)
filepath <- outpath
}
if(substring(filepath, nchar(filepath)-2, nchar(filepath))==".h5") {
files <- unlist(strsplit(filepath, split="/",
fixed=T))[length(unlist(strsplit(filepath,
split="/", fixed=T)))]
filepath <- paste0(unlist(strsplit(filepath, split="/",
fixed=T))[1:I(length(unlist(strsplit(filepath,
split="/", fixed=T)))-1)],
collapse="/")
} else {
files <- list.files(filepath, recursive=T)
}
if(length(grep(".zip", files))==length(files)) {
for(i in 1:length(files)) {
utils::unzip(paste(filepath, files[i], sep="/"), exdir=filepath)
}
files <- list.files(filepath, recursive=T)
}
files <- files[grep(".h5", files)]
tableList <- vector("list", length(files))
names(tableList) <- substring(files, 1, nchar(files)-3)
pb <- utils::txtProgressBar(style=3)
for(i in 1:length(files)) {
listObj <- base::try(rhdf5::h5ls(paste(filepath, files[i], sep="/")), silent=T)
if(class(listObj)=="try-error") {
stop(paste("\n", paste(filepath, files[i], sep="/"), " could not be read.", sep=""))
}
listDataObj <- listObj[listObj$otype == "H5I_DATASET",]
listDataName <- base::paste(listDataObj$group, listDataObj$name, sep = "/")
# filter by variable/level selections
levelInd <- grep(level, listDataName)
if(level!="dp04" & level!="dp03" & level!="dp02" & !all(is.na(var))) {
varInd <- which(listDataObj$name %in% var)
} else {
varInd <- 1:length(listDataName)
}
if(level!="dp04" & level!="dp03" & level!="dp02" & !is.na(avg)) {
avgInd <- grep(paste(avg, "m", sep=""), listDataName)
} else {
if(level=="dp01") {
stop("If level=='dp01', avg is a required input.")
} else {
avgInd <- 1:length(listDataName)
}
}
# exclude footprint grid data
if(length(grep("foot/grid", listDataName))>0) {
gridInd <- grep("foot/grid", listDataName, invert=T)
} else {
gridInd <- 1:length(listDataName)
}
ind <- intersect(intersect(levelInd, intersect(varInd, avgInd)), gridInd)
# check that you haven't filtered to nothing
if(length(ind)==0) {
stop(paste("There are no data meeting the criteria level ", level,
", averaging interval ", avg, ", and variables ", var, sep=""))
}
listDataName <- listDataName[ind]
tableList[[i]] <- base::lapply(listDataName, rhdf5::h5read,
file=paste(filepath, files[i], sep="/"))
base::names(tableList[[i]]) <- substring(listDataName, 2, nchar(listDataName))
utils::setTxtProgressBar(pb, i/length(files))
}
close(pb)
tabs <- character()
for(k in 1:length(tableList)) {
tabs <- c(tabs, names(tableList[[k]]))
}
tabs <- unique(tabs)
timeMergList <- vector("list", length(tabs))
names(timeMergList) <- tabs
pb2 <- utils::txtProgressBar(style=3)
for(j in 1:length(timeMergList)) {
# table to concatenate
nm <- names(timeMergList)[j]
# subset to one site at a time
tableListSub <- tableList[grep(substring(nm, 1, 4), names(tableList))]
# get full set of variable names for the table to concatenate
colN <- character()
for(k in 1:length(tableListSub)) {
colN <- c(colN, names(tableListSub[[k]][[nm]]))
}
colN <- unique(colN)
# stack the tables
tempDF <- data.frame(rep(NA, length(colN)))
tempDF <- t(tempDF)
colnames(tempDF) <- colN
timeMergList[[j]] <- tempDF
for(k in 1:length(tableListSub)) {
timeMergList[[j]] <- rbind(timeMergList[[j]], tableListSub[[k]][[nm]])
}
timeMergList[[j]] <- timeMergList[[j]][-1,]
utils::setTxtProgressBar(pb2, j/length(timeMergList))
}
close(pb2)
v <- getVarsEC("/Users/clunch/Desktop/filesToStack00200/NEON.D10.CPER.DP4.00200.001.nsae.2017-12.basic.h5")
View(v)
sites <- unique(substring(names(timeMergList), 1, 4))
varMergList <- vector("list", length(sites)+1)
names(varMergList) <- c(sites, "variables")
pb3 <- utils::txtProgressBar(style=3)
idx <- 0
m <- 1
timeMergPerSite <- timeMergList[grep(sites[m], names(timeMergList))]
names(timeMergPerSite)
strsplit(names(timeMergPerSite))
strsplit(names(timeMergPerSite), split="/", fixed=T)
namesSpl <- unlist(strsplit(names(timeMergPerSite), split="/", fixed=T))
namesSpl <- matrix(unlist(strsplit(names(timeMergPerSite), split="/", fixed=T)),
nrow(length(names(timeMergPerSite))))
namesSpl <- matrix(unlist(strsplit(names(timeMergPerSite), split="/", fixed=T)),
nrow=length(names(timeMergPerSite)))
View(namesSpl)
namesSpl <- matrix(unlist(strsplit(names(timeMergPerSite), split="/", fixed=T)),
nrow=length(names(timeMergPerSite)), byrow=T)
View(namesSpl)
horver <- tidyr::separate(namesSpl, col="V5",
into=c("hor", "ver", "tmi"),
sep="_", fill="left")
namesSpl <- data.frame(matrix(unlist(strsplit(names(timeMergPerSite), split="/", fixed=T)),
nrow=length(names(timeMergPerSite)), byrow=T))
horver <- tidyr::separate(namesSpl, col="V5",
into=c("hor", "ver", "tmi"),
sep="_", fill="left")
View(namesSpl)
horver <- tidyr::separate(namesSpl, col="X5",
into=c("hor", "ver", "tmi"),
sep="_", fill="left")
View(horver)
names(timeMergList)
namesSpl <- data.frame(matrix(unlist(strsplit(names(timeMergList), split="/", fixed=T)),
nrow=length(names(timeMergList)), byrow=T))
horver <- tidyr::separate(namesSpl, col="X5",
into=c("hor", "ver", "tmi"),
sep="_", fill="left")
View(horver)
verSpl <- tidyr::separate(namesSpl, col="X5",
into=c("hor", "ver", "tmi"),
sep="_", fill="left")
View(timeMergList[[1]])
View(timeMergList[[1]])
par <- loadByProduct(dpID="DP1.00024.001", site="HARV", startdate="2018-03", enddate="2018-03", avg=30)
View(par)
View(par$PARPAR_30min)
View(par$PARPAR_30min)
for(n in 1:length(timeMergList)) {
verticalPosition <- rep(verSpl$ver[n], nrow(timeMergList[[n]]))
timeMergList[[n]] <- cbind(verticalPosition, timeMergList[[n]])
}
View(timeMergList[[3]])
head(names(timeMergList))
names(verSpl)
profNames <- paste0(verSpl[,grep("X", names(verSpl))], collapse="/")
profNames
profNames <- apply(verSpl[,grep("X", names(verSpl))], 2, paste0, collapse="/")
profNames <- apply(verSpl[,grep("X", names(verSpl))], 1, paste0, collapse="/")
profNames
profTabs <- unique(profNames)
verMergList <- vector("list", length(profTabs))
names(verMergList) <- profTabs
library(jsonlite)
library(httr)
username <- "ccc5ed112836c62496dfc6cf6afeeea9"
wkid <- "1262158"
req <- GET("https://toggl.com/reports/api/v2/summary",
authenticate(user=username, password="api_token"),
query=list(user_agent="clunch", workspace_id=wkid, since=Sys.Date()))
parsed <- fromJSON(content(req, "text"), flatten=T)
timeByWBS <- parsed$data[,c("time","title.project")]
timeByWBS$time <- round(timeByWBS$time/(60*60*1000), 1)
timeByWBS
devtools::install_github('NEONScience/NEON-utilities/neonUtilities', ref='eddy')
library(neonUtilities)
flux <- stackEddy(filepath="/Users/clunch/Desktop/filesToStack00200/",
level="dp04", var=NA, avg=NA)
temp.prof <- stackEddy(filepath="/Users/clunch/Desktop/filesToStack00200/",
level="dp02", var=NA, avg=NA)
raw.iso <- stackEddy(filepath="/Users/clunch/Desktop/filesToStack00200/NEON.D10.CPER.DP4.00200.001.nsae.2018-02.basic.h5",
level="dp01", var=c("rtioMoleDry12CCo2","rtioMoleDry13CCo2"), avg=9)
library(neonUtilities)
ft <- footRaster("/Users/clunch/Desktop/expanded/filesToStack00200")
raster::plot(ft, 1)
library(jsonlite)
library(httr)
username <- "ccc5ed112836c62496dfc6cf6afeeea9"
wkid <- "1262158"
req <- GET("https://toggl.com/reports/api/v2/summary",
authenticate(user=username, password="api_token"),
query=list(user_agent="clunch", workspace_id=wkid, since=Sys.Date()))
parsed <- fromJSON(content(req, "text"), flatten=T)
timeByWBS <- parsed$data[,c("time","title.project")]
timeByWBS$time <- round(timeByWBS$time/(60*60*1000), 1)
timeByWBS
library(jsonlite)
library(httr)
username <- "ccc5ed112836c62496dfc6cf6afeeea9"
wkid <- "1262158"
req <- GET("https://toggl.com/reports/api/v2/summary",
authenticate(user=username, password="api_token"),
query=list(user_agent="clunch", workspace_id=wkid, since=Sys.Date()))
parsed <- fromJSON(content(req, "text"), flatten=T)
timeByWBS <- parsed$data[,c("time","title.project")]
timeByWBS$time <- round(timeByWBS$time/(60*60*1000), 1)
timeByWBS
592*883
592*1038
638*883
1038-883
library(jsonlite)
library(httr)
username <- "ccc5ed112836c62496dfc6cf6afeeea9"
wkid <- "1262158"
req <- GET("https://toggl.com/reports/api/v2/summary",
authenticate(user=username, password="api_token"),
query=list(user_agent="clunch", workspace_id=wkid, since="2019-07-18"))
parsed <- fromJSON(content(req, "text"), flatten=T)
timeByWBS <- parsed$data[,c("time","title.project")]
timeByWBS$time <- round(timeByWBS$time/(60*60*1000), 1)
timeByWBS
46*2
92+63
155/2
library(jsonlite)
library(httr)
username <- "ccc5ed112836c62496dfc6cf6afeeea9"
wkid <- "1262158"
req <- GET("https://toggl.com/reports/api/v2/summary",
authenticate(user=username, password="api_token"),
query=list(user_agent="clunch", workspace_id=wkid, since="2019-07-23"))
parsed <- fromJSON(content(req, "text"), flatten=T)
timeByWBS <- parsed$data[,c("time","title.project")]
timeByWBS$time <- round(timeByWBS$time/(60*60*1000), 1)
timeByWBS
library(jsonlite)
library(httr)
username <- "ccc5ed112836c62496dfc6cf6afeeea9"
wkid <- "1262158"
req <- GET("https://toggl.com/reports/api/v2/summary",
authenticate(user=username, password="api_token"),
query=list(user_agent="clunch", workspace_id=wkid, since=Sys.Date()))
parsed <- fromJSON(content(req, "text"), flatten=T)
timeByWBS <- parsed$data[,c("time","title.project")]
timeByWBS$time <- round(timeByWBS$time/(60*60*1000), 1)
timeByWBS
227/178
560/430
library(neonUtilities)
stackByTable("/Users/clunch/Downloads/NEON_chem-wet-dep.zip")
library(jsonlite)
library(httr)
username <- "ccc5ed112836c62496dfc6cf6afeeea9"
wkid <- "1262158"
req <- GET("https://toggl.com/reports/api/v2/summary",
authenticate(user=username, password="api_token"),
query=list(user_agent="clunch", workspace_id=wkid, since=Sys.Date()))
parsed <- fromJSON(content(req, "text"), flatten=T)
timeByWBS <- parsed$data[,c("time","title.project")]
timeByWBS$time <- round(timeByWBS$time/(60*60*1000), 1)
timeByWBS
library(jsonlite)
library(httr)
username <- "ccc5ed112836c62496dfc6cf6afeeea9"
wkid <- "1262158"
req <- GET("https://toggl.com/reports/api/v2/summary",
authenticate(user=username, password="api_token"),
query=list(user_agent="clunch", workspace_id=wkid, since="2019-08-08"))
parsed <- fromJSON(content(req, "text"), flatten=T)
timeByWBS <- parsed$data[,c("time","title.project")]
timeByWBS$time <- round(timeByWBS$time/(60*60*1000), 1)
timeByWBS
devtools::install_github('NEONScience/NEON-geolocation/geoNEON')
neonUtilities::zipsByProduct(dpID='DP1.10098.001', site='WREF', package='expanded', savepath='/Users/clunch/Desktop')
neonUtilities::stackByTable('/Users/clunch/Desktop/filesToStack10098', folder=T, savepath='envt')
install.packages('neonUtilities')
tst <- neonUtilities::loadByProduct(dpID='DP1.10098.001', site='WREF')
library(neonUtilities)
scc <- loadByProduct(dpID='DP1.10081.001', package='expanded', site='WREF')
scc <- loadByProduct(dpID='DP1.10081.001', package='expanded', site='SOAP')
scc <- loadByProduct(dpID='DP1.10081.001', package='expanded', site='DEJU')
zipsByProduct(dpID='DP1.10081.001', package='expanded', site='DEJU',
savepath='/Users/clunch/Desktop')
57*200
library(neonUtilities)
sim <- stackByTable('/Users/clunch/Downloads/NEON_site-mgt-and-event-report.zip',
savepath='envt')
View(sim$sim_eventData)
options(repos = )
options()$repos
options()$repos
install.packages("hms", repos="https://cran.rstudio.com/")
install.packages("hms", repos="https://cloud.r-project.org")
library(raster)
library(gtools)
library(purrr)
library(magick)
install.packages('magick')
library(magick)
library(neonUtilities)
zipsByProduct(dpID='DP4.00200.001', site='WREF', startdate='2018-08', enddate='2018-08', package='expanded', check.size=F, savepath='/Users/clunch/Desktop/expandedWREF')
ft <- footRaster('/Users/clunch/Desktop/expandedWREF/filesToStack00200/NEON.D16.WREF.DP4.00200.001.2018-08.expanded.20190718T193727Z/NEON.D16.WREF.DP4.00200.001.nsae.2018-08-03.expanded.h5')
source('~/GitHub/NEON-utilities/neonUtilities/R/footRaster.R')
ft <- footRaster('/Users/clunch/Desktop/expandedWREF/filesToStack00200/NEON.D16.WREF.DP4.00200.001.2018-08.expanded.20190718T193727Z/NEON.D16.WREF.DP4.00200.001.nsae.2018-08-03.expanded.h5')
raster::filledContour(ft[[1]], col=topo.colors(24),
xlim=c(0.4,0.6), ylim=c(0.4,0.6),
levels=0.001*0:24)
ft
max(ft)
library(raster)
library(gtools)
library(purrr)
library(magick)
setwd("~/GitHub/sandbox/animation/gif_layers/")
make.png <- function(x) {
for (i in 1:nlayers(x)) {
par(bty='n')
png(filename=paste0('x_',i,'.png'), bg='white', height=1024, width=1024, res=200)
#plot(x[[i]], main=substring(names(x)[i],84,103), colNA='white', col=topo.colors(24))
raster::filledContour(x[[i]], col=topo.colors(51),
xlim=c(0.4,0.6), ylim=c(0.4,0.6),
levels=0.001*0:50,
main=substring(names(x)[i],84,103))
# need to suppress axes but not legend scale
dev.off()
}
}
make.png(ft[[2:48]])
gif.create <- function(names='.png', file.out='x.gif', clear=c(TRUE,FALSE)) {
mixedsort(list.files(path=getwd(), pattern=names)) %>%
map(image_read) %>% # reads each path file
image_join() %>% # join images
image_animate(fps=2) %>% # animate
image_write(file.out) # write to file
if (clear==TRUE) {
unlink('*.png') # delete individual png files
}
}
gif.create(clear=F)
ft <- footRaster('/Users/clunch/Desktop/expandedWREF/filesToStack00200/NEON.D16.WREF.DP4.00200.001.2018-08.expanded.20190718T193727Z/NEON.D16.WREF.DP4.00200.001.nsae.2018-08-07.expanded.h5')
make.png(ft[[2:48]])
gif.create(clear=F)
ft <- footRaster('/Users/clunch/Desktop/expandedWREF/filesToStack00200/NEON.D16.WREF.DP4.00200.001.2018-08.expanded.20190718T193727Z/NEON.D16.WREF.DP4.00200.001.nsae.2018-08-19.expanded.h5')
make.png(ft[[2:48]])
gif.create(clear=F)
ft <- footRaster('/Users/clunch/Desktop/expandedWREF/filesToStack00200/NEON.D16.WREF.DP4.00200.001.2018-08.expanded.20190718T193727Z/NEON.D16.WREF.DP4.00200.001.nsae.2018-08-03.expanded.h5')
make.png(ft[[2:48]])
gif.create(clear=F)
make.png <- function(x) {
for (i in 1:nlayers(x)) {
par(bty='n')
png(filename=paste0('x_',i,'.png'), bg='white', height=1024, width=1024, res=200)
#plot(x[[i]], main=substring(names(x)[i],84,103), colNA='white', col=topo.colors(24))
raster::filledContour(x[[i]], col=topo.colors(41),
xlim=c(0.42,0.58), ylim=c(0.42,0.58),
levels=0.001*0:40,
main=substring(names(x)[i],84,103))
# need to suppress axes but not legend scale
dev.off()
}
}
make.png(ft[[2:48]])
gif.create(clear=F)
make.png <- function(x) {
for (i in 1:nlayers(x)) {
par(bty='n')
png(filename=paste0('x_',i,'.png'), bg='white', height=1024, width=1224, res=200)
#plot(x[[i]], main=substring(names(x)[i],84,103), colNA='white', col=topo.colors(24))
raster::filledContour(x[[i]], col=topo.colors(41),
xlim=c(0.42,0.58), ylim=c(0.42,0.58),
levels=0.001*0:40,
main=substring(names(x)[i],84,103))
# need to suppress axes but not legend scale
dev.off()
}
}
make.png(ft[[2:48]])
gif.create(clear=F)
